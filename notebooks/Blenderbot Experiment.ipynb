{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92cfd454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:10px !important; } .container { width:95% !important; } .end_space { min-height:5px !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This gets rid of Jupyter's screen-realestate-wating-margin-of-gray.\n",
    "#\n",
    "\n",
    "from IPython.core.display import display, HTML, Markdown\n",
    "display(HTML(\n",
    "    '<style>'\n",
    "        '#notebook { padding-top:10px !important; } ' \n",
    "        '.container { width:95% !important; } '\n",
    "        '.end_space { min-height:5px !important; } '\n",
    "    '</style>'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6961f",
   "metadata": {},
   "source": [
    "# Customize Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9200b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust these directories to where you put your stuff\n",
    "import os\n",
    "\n",
    "commonsRoot = os.path.expanduser(\"~/IdeaProjects/commons\")                           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66453fc",
   "metadata": {},
   "source": [
    "# Set up Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ba5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Include the Python codes in the recommendations project into Jupyter's libraries\n",
    "#\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "for d in [commonsRoot, ]:\n",
    "    sourceDir = d + '/src/main'\n",
    "    if sourceDir not in sys.path:\n",
    "        sys.path.append(sourceDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a51f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30c6704",
   "metadata": {},
   "source": [
    "# Experiment with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e2281ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2666359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b180377de3334af39eb7475821df8d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84e5762ae084a27af397347e56d23a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c15c07480c4cc9b8487e6f79695dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/124k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c450815bf1b14998bb90110de1204831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/61.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36047fd69eb24db1af7ca03daa769d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce284346a114f7198255cd5bd4fe861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd8dc3277884ab0ac6d80513e078661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<s> That's unfortunate. Are they trying to lose weight or are they just trying to be healthier?</s>\"]\n",
      "7.457543134689331\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# mname = \"facebook/blenderbot-400M-distill\"\n",
    "mname = \"facebook/blenderbot-1B-distill\"\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)\n",
    "UTTERANCE = \"My friends are cool but they eat too many carbs.\"\n",
    "\n",
    "statTime = time.time()\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n",
    "reply_ids = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(reply_ids))\n",
    "print(time.time() - statTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee00d6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<s> That's what I was thinking, but I don't know if I want to risk it.</s>\"]\n",
      "7.560004711151123\n"
     ]
    }
   ],
   "source": [
    "statTime = time.time()\n",
    "UTTERANCE = \"no, they just like sweets\"\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n",
    "reply_ids = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(reply_ids))\n",
    "print(time.time() - statTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cadabd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<s> I love it! It's one of the most popular foods in the world. What do you like to eat?</s>\"]\n",
      "7.227740049362183\n"
     ]
    }
   ],
   "source": [
    "statTime = time.time()\n",
    "# UTTERANCE = '''\n",
    "# your persona: I like cheese\n",
    "# your persona: I am from New York City\n",
    "# Hi, where are you from\n",
    "# i ' m from the city of new york . i love cheese . what do you like to eat ?\n",
    "# do you like cheese?\n",
    "# yes , i love it . it ' s one of my favorite foods . what ' s your favorite food ?\n",
    "# do you know what is piave?\n",
    "# '''\n",
    "UTTERANCE = '''\n",
    "you: I like cheese\n",
    "you: I am from New York City\n",
    "Hi, how are you?  Do you like Piave?\n",
    "'''\n",
    "\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\", padding=True)\n",
    "reply_ids = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(reply_ids))\n",
    "print(time.time() - statTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "772df1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 206,   96,  512,  800,   72,   33,  281,  398, 4686,  206,   96,  512,\n",
       "          800,   72,   33,  281,  632,  482, 2310, 6210, 5203,  206,  206,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a3630",
   "metadata": {},
   "source": [
    "# Experiment with ParlAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2c860",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "```\n",
    "pip install parlai\n",
    "pip install subword-nmt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86b2ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:04:56 | loading dictionary from /Users/cjwang/opt/anaconda3/lib/python3.7/site-packages/data/models/blender/blender_3B/model.dict\n",
      "14:04:57 | num words = 8008\n",
      "14:05:25 | Total parameters: 2,696,268,800 (2,695,613,440 trainable)\n",
      "14:05:25 | Loading existing model params from /Users/cjwang/opt/anaconda3/lib/python3.7/site-packages/data/models/blender/blender_3B/model\n",
      "You said: your persona: I like cheese\n",
      "your persona: I am from New York City\n",
      "Hi, where are you from\n",
      "BlenderBot replied: I'm from the city of New York, the most populous city in the United States.\n",
      "15.416275978088379\n",
      "\n",
      "You said: do you like cheese?\n",
      "BlenderBot replied: Yes, I love cheese.  It's one of my favorite foods.  What about you?\n",
      "16.74525499343872\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "BlenderBot's history view:\n",
      "your persona: I like cheese\n",
      "your persona: I am from New York City\n",
      "Hi, where are you from  I'm from the city of New York, the most populous city in the United States.  do you like cheese?  Yes, I love cheese.  It's one of my favorite foods.  What about you?\n"
     ]
    }
   ],
   "source": [
    "from parlai.core.agents import create_agent_from_model_file\n",
    "# blender_agent = create_agent_from_model_file(\"zoo:blender/blender_400M/model\")\n",
    "blender_agent = create_agent_from_model_file(\"zoo:blender/blender_3B/model\")\n",
    "\n",
    "# forget everything. Important if you run this multiple times.\n",
    "blender_agent.reset()\n",
    "\n",
    "# concatenate the persona and the first thing the human says\n",
    "first_turn = \"\\n\".join([\n",
    "    \"your persona: I like cheese\",\n",
    "    \"your persona: I am from New York City\",\n",
    "    \"Hi, where are you from\"\n",
    "])\n",
    "# Model actually witnesses the human's text\n",
    "blender_agent.observe({'text': first_turn, 'episode_done': False})\n",
    "print(f\"You said: {first_turn}\")\n",
    "\n",
    "# model produces a response\n",
    "startTime = time.time()\n",
    "response = blender_agent.act()\n",
    "print(\"BlenderBot replied: {}\".format(response['text']))\n",
    "print(time.time() - startTime)\n",
    "print()\n",
    "\n",
    "# now another turn\n",
    "second_turn = \"do you like cheese?\"\n",
    "print(f\"You said: {second_turn}\")\n",
    "\n",
    "startTime = time.time()\n",
    "blender_agent.observe({'text': second_turn, \"episode_done\": False})\n",
    "response2 = blender_agent.act()\n",
    "print(\"BlenderBot replied: {}\".format(response2['text']))\n",
    "print(time.time() - startTime)\n",
    "\n",
    "print()\n",
    "print('-' * 40)\n",
    "print()\n",
    "print(\"BlenderBot's history view:\")\n",
    "print(blender_agent.history.get_history_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58a870fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlenderBot replied: I've never been to New Jersey, but I've heard it's a nice place to visit.\n",
      "33.50209093093872\n",
      "BlenderBot's history view:\n",
      "your persona: I like cheese\n",
      "your persona: I am from New York City\n",
      "Hi, where are you from  I'm from the city of New York, the most populous city in the United States.  do you like cheese?  Yes, I love cheese.  It's one of my favorite foods.  What about you?  how long do you take to go to the Jersey City?  I've never been to New Jersey, but I've heard it's a nice place to visit.\n"
     ]
    }
   ],
   "source": [
    "# more turns from CJ\n",
    "# third_turn = \"do you know what is piave?\"\n",
    "third_turn = \"how long do you take to go to the Jersey City?\"\n",
    "\n",
    "startTime = time.time()\n",
    "blender_agent.observe({'text': third_turn, \"episode_done\": False})\n",
    "response3 = blender_agent.act()\n",
    "print(\"BlenderBot replied: {}\".format(response3['text']))\n",
    "print(time.time() - startTime)\n",
    "\n",
    "print(\"BlenderBot's history view:\")\n",
    "print(blender_agent.history.get_history_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e1da07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'TransformerGenerator',\n",
       " 'episode_done': False,\n",
       " 'text': \"I've never been to New Jersey, but I've heard it's a nice place to visit.\",\n",
       " 'beam_texts': [(\"I've never been to New Jersey, but I've heard it's a nice place to visit.\",\n",
       "   -6.780792713165283),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, though.\",\n",
       "   -7.047243595123291),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated city in New York State.\",\n",
       "   -7.1058454513549805),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in Pennsylvania.\",\n",
       "   -7.14259672164917),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia though.\",\n",
       "   -7.26740026473999),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated state in the US.\",\n",
       "   -7.279247283935547),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated city in America.\",\n",
       "   -7.352784156799316),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is also in the New York metropolitan area.\",\n",
       "   -7.391134262084961),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated urban area in the US.\",\n",
       "   -7.455860137939453),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated urban area in the world.\",\n",
       "   -7.512598991394043),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in New York State.\",\n",
       "   -7.687839031219482),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in PA.\",\n",
       "   -7.730276584625244),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second largest city in New York State.\",\n",
       "   -7.928862571716309),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, though, and it's a great city.\",\n",
       "   -7.980947017669678),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, though, which is the second-largest city in New York State.\",\n",
       "   -7.99509334564209),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in New York.\",\n",
       "   -8.067826271057129),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is also in New York.\",\n",
       "   -8.07827377319336),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city.\",\n",
       "   -8.090593338012695),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, though, which is the second-largest city in PA.\",\n",
       "   -8.093864440917969),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is also in the New York metro area.\",\n",
       "   -8.117423057556152),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in New York state.\",\n",
       "   -8.121554374694824),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second largest city.\",\n",
       "   -8.177988052368164),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is also in the New York metropolitan area. \",\n",
       "   -8.185507774353027),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second largest city in New York.\",\n",
       "   -8.254595756530762),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in Pennsylvania\",\n",
       "   -8.348832130432129),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in New York State. \",\n",
       "   -8.578437805175781)],\n",
       " 'metrics': {'clen': AverageMetric(94),\n",
       "  'ctrunc': AverageMetric(0),\n",
       "  'ctrunclen': AverageMetric(0),\n",
       "  'gen_n_toks': AverageMetric(23)}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16060ea0",
   "metadata": {},
   "source": [
    "# Use Conversational Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c1125507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Conversation, ConversationalPipeline\n",
    "from flask import Flask\n",
    "from flask import request, jsonify\n",
    "\n",
    "modelName = \"facebook/blenderbot-1B-distill\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(modelName)\n",
    "nlp = ConversationalPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "conversation = Conversation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b47d726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(text):\n",
    "    conversation.add_user_input(text)\n",
    "    result = nlp([conversation], do_sample=False, max_length=1000)\n",
    "    \n",
    "    print(str(result))\n",
    "    print(f\">>>> {list(result.iter_texts())[-1]}\")\n",
    "    *_, last = result.iter_texts()\n",
    "    print(last)\n",
    "#     for is_user, text in result.iter_texts():\n",
    "#         who = \"Me:\" if is_user else \"Bot:\"\n",
    "#         print(f\"{who} {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e3f45a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    global conversation\n",
    "    conversation = Conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "30353261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persona(text):\n",
    "    conversation.add_user_input('Hello')\n",
    "    conversation.append_response(text)\n",
    "        \n",
    "    # Put the user's messages as \"old message\".\n",
    "    conversation.mark_processed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a221006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset()\n",
    "persona(\"I live in New York City.  I like cheese.  I jog everyday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d147277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trimmed input from conversation as it was longer than 128 tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 9c749996-8d66-4778-a4d9-7f12d6502af8 \n",
      "user >> Hello \n",
      "bot >> I live in New York City.  I like cheese.  I jog everyday. \n",
      "user >> Empire State Building is NOT a park.  Do you run up and down the stairs? \n",
      "bot >>  Yes, I do.  It is the most populous city in the United States. \n",
      "user >> Empire State Building is NOT a park.  Do you run up and down the stairs? \n",
      "bot >>  No, I don't.  The stairs are too steep for me to run up. \n",
      "user >> Empire State Building is NOT a park.  Do you run up and down the stairs? \n",
      "bot >>  No, but I do jog on the staircase.  That is the only way I can jog. \n",
      "\n",
      ">>>> (False, ' No, but I do jog on the staircase.  That is the only way I can jog.')\n",
      "(False, ' No, but I do jog on the staircase.  That is the only way I can jog.')\n",
      "None\n",
      "9.312549114227295\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "print(chat(\"Empire State Building is NOT a park.  Do you run up and down the stairs?\"))\n",
    "print(time.time() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c9f34193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add_user_input',\n",
       " 'append_response',\n",
       " 'generated_responses',\n",
       " 'iter_texts',\n",
       " 'mark_processed',\n",
       " 'new_user_input',\n",
       " 'past_user_inputs',\n",
       " 'uuid']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_user_input(\"I like NYC\")\n",
    "result = nlp([conversation], do_sample=False, max_length=1000)\n",
    "dir(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (recommendations)",
   "language": "python",
   "name": "pycharm-7e18e330"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
