{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f583e85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mj/8vz4yhqj5w76hnkw54qktw900000gn/T/ipykernel_208/3664963009.py:4: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML, Markdown\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:10px !important; } .container { width:95% !important; } .end_space { min-height:5px !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This gets rid of Jupyter's screen-realestate-wating-margin-of-gray.\n",
    "#\n",
    "\n",
    "from IPython.core.display import display, HTML, Markdown\n",
    "display(HTML(\n",
    "    '<style>'\n",
    "        '#notebook { padding-top:10px !important; } ' \n",
    "        '.container { width:95% !important; } '\n",
    "        '.end_space { min-height:5px !important; } '\n",
    "    '</style>'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e04c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version \n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe16f17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 or 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39da7b",
   "metadata": {},
   "source": [
    "# Customize Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf04d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust these directories to where you put your stuff\n",
    "import os\n",
    "\n",
    "commonsRoot = os.path.expanduser(\"~/IdeaProjects/commons\")                           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd58230",
   "metadata": {},
   "source": [
    "# Set up Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71450fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Include the Python codes in the recommendations project into Jupyter's libraries\n",
    "#\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "for d in [commonsRoot, ]:\n",
    "    sourceDir = d + '/src/main'\n",
    "    if sourceDir not in sys.path:\n",
    "        sys.path.append(sourceDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7102baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b952848",
   "metadata": {},
   "source": [
    "# Experiment with Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a90b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40fc785c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b180377de3334af39eb7475821df8d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84e5762ae084a27af397347e56d23a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c15c07480c4cc9b8487e6f79695dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/124k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c450815bf1b14998bb90110de1204831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/61.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36047fd69eb24db1af7ca03daa769d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce284346a114f7198255cd5bd4fe861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd8dc3277884ab0ac6d80513e078661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<s> That's unfortunate. Are they trying to lose weight or are they just trying to be healthier?</s>\"]\n",
      "7.457543134689331\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# mname = \"facebook/blenderbot-400M-distill\"\n",
    "mname = \"facebook/blenderbot-1B-distill\"\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)\n",
    "UTTERANCE = \"My friends are cool but they eat too many carbs.\"\n",
    "\n",
    "statTime = time.time()\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n",
    "reply_ids = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(reply_ids))\n",
    "print(time.time() - statTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68c2e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<s> That's what I was thinking, but I don't know if I want to risk it.</s>\"]\n",
      "7.560004711151123\n"
     ]
    }
   ],
   "source": [
    "statTime = time.time()\n",
    "UTTERANCE = \"no, they just like sweets\"\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\")\n",
    "reply_ids = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(reply_ids))\n",
    "print(time.time() - statTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ea0989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"<s> I love it! It's one of the most popular foods in the world. What do you like to eat?</s>\"]\n",
      "7.227740049362183\n"
     ]
    }
   ],
   "source": [
    "statTime = time.time()\n",
    "# UTTERANCE = '''\n",
    "# your persona: I like cheese\n",
    "# your persona: I am from New York City\n",
    "# Hi, where are you from\n",
    "# i ' m from the city of new york . i love cheese . what do you like to eat ?\n",
    "# do you like cheese?\n",
    "# yes , i love it . it ' s one of my favorite foods . what ' s your favorite food ?\n",
    "# do you know what is piave?\n",
    "# '''\n",
    "UTTERANCE = '''\n",
    "you: I like cheese\n",
    "you: I am from New York City\n",
    "Hi, how are you?  Do you like Piave?\n",
    "'''\n",
    "\n",
    "inputs = tokenizer([UTTERANCE], return_tensors=\"pt\", padding=True)\n",
    "reply_ids = model.generate(**inputs)\n",
    "print(tokenizer.batch_decode(reply_ids))\n",
    "print(time.time() - statTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1766de9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 206,   96,  512,  800,   72,   33,  281,  398, 4686,  206,   96,  512,\n",
       "          800,   72,   33,  281,  632,  482, 2310, 6210, 5203,  206,  206,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93027e44",
   "metadata": {},
   "source": [
    "# Experiment with ParlAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eee447",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "```\n",
    "pip install parlai\n",
    "pip install subword-nmt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef5f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                 /@&%###%&&@@#\n",
      "                      .,*/((((##@@@&%%#%%&&@@@&%%#/*.\n",
      "             #@@&&&%%%%##(((///*****//(((###%%%&&&@@@@@&&%#%%#.\n",
      "         .%&@@@@@&&&%%%####((((////((((####%%%&&&@@@@@&&%%#%%####,\n",
      "           ./,,#(//**,,.....,,,,***////((((########%%%%%%%%###(((\n",
      "              /*(//**,,,....,,,,***////((((########%%%%%%%%###(#%*\n",
      "               (*,...      ...,,,***//////((((((///////(/*...,/#@@@(\n",
      "               **,,..         ...,,,,,,,,,,........,,*///*...*(#@@@@&&*\n",
      "               ./,,..          ...,,,,,,,,,........,,*//*,...*#/,,,,,/%#\n",
      "                (*,..          ...,,,,,,,,,........,,*//*,..,/(      .,#(\n",
      "                **,..          ...,,,,,,,,,.........,*//*,..,((       .,(#\n",
      "                 /*,..          ....,,,,,,,.....  ..,***,,,,(#         ..#&\n",
      "                 **,..          ....,,,,,,,....   ..,***,,,*#.         .,%@\n",
      "                 ./,...       B l e n d e r B o t ...***,,,*#          .*%@\n",
      "                  /*,..          ...,,,,,,,....    .,**,,,,/#         ..(%/\n",
      "                  /*,,..         ...,,,,,,,...    ..,*,,,,,(.         ..#&\n",
      "                  ,/*,..         ...,,,,,,,...    ..,*,,,,*#         ..*%(\n",
      "                   /*,..         ...,,,,,.....    ..,*,*,,/(         ..#&\n",
      "                   /**,..        ...,,,,.....    ...,***,*(.       ,,(%.\n",
      "                    (/*,,..      ....,,.....     ...,****(&@@@&&&#,\n",
      "                     (/*,,...   .....,,......     ..,****#@,\n",
      "                     *(/*,,/....*(###%(,(%%##(*.  ./,,**(\n",
      "                      ,//**(,........,/((#.........*,**(\n",
      "                      .(#//*,,,,,,.*.,/((%/,,.....,,*/@\n",
      "                    ((######//****,/.,/(#%#***,***(&@@@@@(\n",
      "                   *&%%#####%%%%%%%#//(#%&%%&&@@@@@@@@@@@@*\n",
      "                   &&%%%###((((((####%%%%&&&&&@@@@@@@@@@&&@.\n",
      "                  *##%%%##(((((((####%%%%%&&&&@@@@@@@@@&#/*,\n",
      "                 .(##%#/,  .,*((##%%%&&&&%%%#####%&&@&&%#(/*.\n",
      "                 /(###(,   .,*/(##%%%&&&&%%%######%&&&&%#(/*,\n",
      "                */((((*.  ..,//((##%%%%%%%%#######%&&&&%%#(/*,\n",
      "               .//(((/,   .,*//((###%%%%%%########%%&&&%%#((/,.\n",
      "              .&####(((((((((######%%%%%%%%&&&&&&&@@@@@@@@@@@@@#\n",
      "               *&#.   .*/((((#######%%%%%%&&&&&&&@@@@@#/.   (&/\n",
      "13:20:49 | building data: /usr/local/lib/python3.10/site-packages/data/models/blender/blender_3B/BST3B.tgz\n",
      "13:20:49 | Downloading http://parl.ai/downloads/_models/blender/BST3B.tgz to /usr/local/lib/python3.10/site-packages/data/models/blender/blender_3B/BST3B.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading BST3B.tgz: 100%|███████████████| 4.95G/4.95G [01:16<00:00, 65.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:23:14 | \u001b[33mLoading model with `--beam-block-full-context false`\u001b[0m\n",
      "13:23:14 | loading dictionary from /usr/local/lib/python3.10/site-packages/data/models/blender/blender_3B/model.dict\n",
      "13:23:14 | num words = 8008\n",
      "13:23:37 | Total parameters: 2,696,268,800 (2,695,613,440 trainable)\n",
      "13:23:37 | Loading existing model params from /usr/local/lib/python3.10/site-packages/data/models/blender/blender_3B/model\n",
      "You said: your persona: I like cheese\n",
      "your persona: I am from New York City\n",
      "Hi, where are you from\n",
      "BlenderBot replied: I'm from the city of New York, the most populous city in the United States.\n",
      "31.778973817825317\n",
      "\n",
      "You said: do you like cheese?\n",
      "BlenderBot replied: Yes, I love cheese.  It's one of my favorite foods.  What about you?\n",
      "36.910192251205444\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "BlenderBot's history view:\n",
      "your persona: I like cheese\n",
      "your persona: I am from New York City\n",
      "Hi, where are you from  I'm from the city of New York, the most populous city in the United States.  do you like cheese?  Yes, I love cheese.  It's one of my favorite foods.  What about you?\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from parlai.core.agents import create_agent_from_model_file\n",
    "# blender_agent = create_agent_from_model_file(\"zoo:blender/blender_400M/model\")\n",
    "blender_agent = create_agent_from_model_file(\"zoo:blender/blender_3B/model\")\n",
    "# blender_agent = create_agent_from_model_file(\"zoo:bb3/bb3_3B/model\")\n",
    "\n",
    "# forget everything. Important if you run this multiple times.\n",
    "blender_agent.reset()\n",
    "\n",
    "# concatenate the persona and the first thing the human says\n",
    "first_turn = \"\\n\".join([\n",
    "    \"your persona: I like cheese\",\n",
    "    \"your persona: I am from New York City\",\n",
    "    \"Hi, where are you from\"\n",
    "])\n",
    "# Model actually witnesses the human's text\n",
    "blender_agent.observe({'text': first_turn, 'episode_done': False})\n",
    "print(f\"You said: {first_turn}\")\n",
    "\n",
    "# model produces a response\n",
    "startTime = time.time()\n",
    "response = blender_agent.act()\n",
    "print(\"BlenderBot replied: {}\".format(response['text']))\n",
    "print(time.time() - startTime)\n",
    "print()\n",
    "\n",
    "# now another turn\n",
    "second_turn = \"do you like cheese?\"\n",
    "print(f\"You said: {second_turn}\")\n",
    "\n",
    "startTime = time.time()\n",
    "blender_agent.observe({'text': second_turn, \"episode_done\": False})\n",
    "response2 = blender_agent.act()\n",
    "print(\"BlenderBot replied: {}\".format(response2['text']))\n",
    "print(time.time() - startTime)\n",
    "\n",
    "print()\n",
    "print('-' * 40)\n",
    "print()\n",
    "print(\"BlenderBot's history view:\")\n",
    "print(blender_agent.history.get_history_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "902a0671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['your persona: I like cheese\\nyour persona: I am from New York City\\nHi, where are you from',\n",
       " \"I'm from the city of New York, the most populous city in the United States.\",\n",
       " 'do you like cheese?',\n",
       " \"Yes, I love cheese.  It's one of my favorite foods.  What about you?\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blender_agent.history.history_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9c36e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_person_tokens',\n",
       " '_global_end_token',\n",
       " '_update_raw_strings',\n",
       " '_update_strings',\n",
       " '_update_vecs',\n",
       " 'add_p1_after_newln',\n",
       " 'add_person_tokens',\n",
       " 'add_reply',\n",
       " 'delimiter',\n",
       " 'delimiter_tok',\n",
       " 'dict',\n",
       " 'field',\n",
       " 'get_history_str',\n",
       " 'get_history_vec',\n",
       " 'get_history_vec_list',\n",
       " 'history_raw_strings',\n",
       " 'history_strings',\n",
       " 'history_vecs',\n",
       " 'max_len',\n",
       " 'p1_token',\n",
       " 'p2_token',\n",
       " 'parse',\n",
       " 'reset',\n",
       " 'reversed',\n",
       " 'size',\n",
       " 'split_on_newln',\n",
       " 'temp_history',\n",
       " 'update_history']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(blender_agent.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "419af1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlenderBot replied: I've never been to New Jersey, but I've heard it's a nice place to visit.\n",
      "33.50209093093872\n",
      "BlenderBot's history view:\n",
      "your persona: I like cheese\n",
      "your persona: I am from New York City\n",
      "Hi, where are you from  I'm from the city of New York, the most populous city in the United States.  do you like cheese?  Yes, I love cheese.  It's one of my favorite foods.  What about you?  how long do you take to go to the Jersey City?  I've never been to New Jersey, but I've heard it's a nice place to visit.\n"
     ]
    }
   ],
   "source": [
    "# more turns from CJ\n",
    "# third_turn = \"do you know what is piave?\"\n",
    "third_turn = \"how long do you take to go to the Jersey City?\"\n",
    "\n",
    "startTime = time.time()\n",
    "blender_agent.observe({'text': third_turn, \"episode_done\": False})\n",
    "response3 = blender_agent.act()\n",
    "print(\"BlenderBot replied: {}\".format(response3['text']))\n",
    "print(time.time() - startTime)\n",
    "\n",
    "print(\"BlenderBot's history view:\")\n",
    "print(blender_agent.history.get_history_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad9d2d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'TransformerGenerator',\n",
       " 'episode_done': False,\n",
       " 'text': \"I've never been to New Jersey, but I've heard it's a nice place to visit.\",\n",
       " 'beam_texts': [(\"I've never been to New Jersey, but I've heard it's a nice place to visit.\",\n",
       "   -6.780792713165283),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, though.\",\n",
       "   -7.047243595123291),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated city in New York State.\",\n",
       "   -7.1058454513549805),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in Pennsylvania.\",\n",
       "   -7.14259672164917),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia though.\",\n",
       "   -7.26740026473999),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated state in the US.\",\n",
       "   -7.279247283935547),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated city in America.\",\n",
       "   -7.352784156799316),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is also in the New York metropolitan area.\",\n",
       "   -7.391134262084961),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated urban area in the US.\",\n",
       "   -7.455860137939453),\n",
       "  (\"I've never been, but I'd love to go.  I hear it's the most densely populated urban area in the world.\",\n",
       "   -7.512598991394043),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in New York State.\",\n",
       "   -7.687839031219482),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in PA.\",\n",
       "   -7.730276584625244),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second largest city in New York State.\",\n",
       "   -7.928862571716309),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, though, and it's a great city.\",\n",
       "   -7.980947017669678),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, though, which is the second-largest city in New York State.\",\n",
       "   -7.99509334564209),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in New York.\",\n",
       "   -8.067826271057129),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is also in New York.\",\n",
       "   -8.07827377319336),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city.\",\n",
       "   -8.090593338012695),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, though, which is the second-largest city in PA.\",\n",
       "   -8.093864440917969),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is also in the New York metro area.\",\n",
       "   -8.117423057556152),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in New York state.\",\n",
       "   -8.121554374694824),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second largest city.\",\n",
       "   -8.177988052368164),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is also in the New York metropolitan area. \",\n",
       "   -8.185507774353027),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second largest city in New York.\",\n",
       "   -8.254595756530762),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in Pennsylvania\",\n",
       "   -8.348832130432129),\n",
       "  (\"I've never been to New Jersey, but I hear it's nice.  I've been to Philadelphia, which is the second-largest city in New York State. \",\n",
       "   -8.578437805175781)],\n",
       " 'metrics': {'clen': AverageMetric(94),\n",
       "  'ctrunc': AverageMetric(0),\n",
       "  'ctrunclen': AverageMetric(0),\n",
       "  'gen_n_toks': AverageMetric(23)}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d0bfc4",
   "metadata": {},
   "source": [
    "# Use Conversational Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74d12a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Conversation, ConversationalPipeline\n",
    "\n",
    "# modelName = \"facebook/blenderbot-1B-distill\"\n",
    "modelName = \"facebook/blenderbot-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(modelName)\n",
    "nlp = ConversationalPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "conversation = Conversation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb704c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(text):\n",
    "    conversation.add_user_input(text)\n",
    "    result = nlp([conversation], do_sample=False, max_length=1000)\n",
    "    \n",
    "    print(str(result))\n",
    "    print(f\">>>> {list(result.iter_texts())[-1]}\")\n",
    "    *_, last = result.iter_texts()\n",
    "    print(last)\n",
    "#     for is_user, text in result.iter_texts():\n",
    "#         who = \"Me:\" if is_user else \"Bot:\"\n",
    "#         print(f\"{who} {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5d4ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    global conversation\n",
    "    conversation = Conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16db8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persona(text):\n",
    "    conversation.add_user_input('Hello')\n",
    "    conversation.append_response(text)\n",
    "        \n",
    "    # Put the user's messages as \"old message\".\n",
    "    conversation.mark_processed()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a007f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset()\n",
    "persona(\"I live in New York City.  I like cheese.  I jog everyday.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b972e6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 74490f51-8722-4e5c-89fe-0dbac8bd1d08 \n",
      "user >> Hello \n",
      "bot >> I live in New York City.  I like cheese.  I jog everyday. \n",
      "user >> You jogged there but you don't know the streets?  Hard to believe \n",
      "bot >>  I know, I know.  It was a long time ago and I was a kid. \n",
      "\n",
      ">>>> (False, ' I know, I know.  It was a long time ago and I was a kid.')\n",
      "(False, ' I know, I know.  It was a long time ago and I was a kid.')\n",
      "None\n",
      "37.14195799827576\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "print(chat(\"You jogged there but you don't know the streets?  Hard to believe\"))\n",
    "print(time.time() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97204b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(True, 'Hello'),\n",
       " (False, 'I live in New York City.  I like cheese.  I jog everyday.'),\n",
       " (True, \"You jogged there but you don't know the streets?  Hard to believe\"),\n",
       " (False, ' I know, I know.  It was a long time ago and I was a kid.'),\n",
       " (True, 'I like NYC'),\n",
       " (False, ' It is a great place to live.  What do you do for a living?.')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(conversation.iter_texts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b80988f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'add_user_input',\n",
       " 'append_response',\n",
       " 'generated_responses',\n",
       " 'iter_texts',\n",
       " 'mark_processed',\n",
       " 'new_user_input',\n",
       " 'past_user_inputs',\n",
       " 'uuid']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_user_input(\"I like NYC\")\n",
    "result = nlp([conversation], do_sample=False, max_length=1000)\n",
    "dir(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
